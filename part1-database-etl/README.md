# Part 1: Database Design & ETL Pipeline

## Objective
This module focuses on cleaning raw CSV data and loading it into a relational
database using an ETL pipeline for FlexiMart, followed by schema documentation
and business query analysis.

---

## Deliverables

### 1. etl_pipeline.py
- Implements data extraction, cleaning, transformation, and loading
  into a SQL database.
- Handles missing values, duplicates, and format inconsistencies.
- Generates a data quality report.

---

### 2. schema_documentation.md
- Documents database entities, relationships, and normalization (3NF).
- Includes sample data representation.

---

### 3. business_queries.sql
- Contains SQL queries for customer history, product analysis,
  and monthly sales trends using joins and aggregations.

---

### 4. data_quality_report.txt
- Auto-generated summary of data quality issues handled during ETL.

---

## Evaluation Criteria Alignment

- ETL Pipeline (15 Marks) → `etl_pipeline.py`
- Schema Documentation (5 Marks) → `schema_documentation.md`
- Business Queries (15 Marks) → `business_queries.sql`

---

## Conclusion
This part demonstrates structured data processing using ETL techniques,
relational database design, and SQL-based business analysis.
